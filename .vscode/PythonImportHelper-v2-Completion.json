[
    {
        "label": "load_model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "tensorflow",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "tensorflow",
        "description": "tensorflow",
        "detail": "tensorflow",
        "documentation": {}
    },
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "YOLO",
        "importPath": "ultralytics",
        "description": "ultralytics",
        "isExtraImport": true,
        "detail": "ultralytics",
        "documentation": {}
    },
    {
        "label": "layers",
        "importPath": "tensorflow.keras",
        "description": "tensorflow.keras",
        "isExtraImport": true,
        "detail": "tensorflow.keras",
        "documentation": {}
    },
    {
        "label": "models",
        "importPath": "tensorflow.keras",
        "description": "tensorflow.keras",
        "isExtraImport": true,
        "detail": "tensorflow.keras",
        "documentation": {}
    },
    {
        "label": "ImageDataGenerator",
        "importPath": "tensorflow.keras.preprocessing.image",
        "description": "tensorflow.keras.preprocessing.image",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing.image",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "preprocess_image",
        "kind": 2,
        "importPath": "cnn_inference",
        "description": "cnn_inference",
        "peekOfCode": "def preprocess_image(image_path, target_size=(128, 128)):\n    \"\"\"\n    Preprocesses the input image:\n    - Loads the image from the given path.\n    - Resizes it to the target size.\n    - Normalizes pixel values between 0 and 1.\n    Returns:\n        The preprocessed image as a NumPy array ready for model inference.\n    \"\"\"\n    # Load the image",
        "detail": "cnn_inference",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "cnn_inference",
        "description": "cnn_inference",
        "peekOfCode": "model = load_model(r'C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\heuristic_cropping_attempt\\5_class_cnn_model.h5')\ndef preprocess_image(image_path, target_size=(128, 128)):\n    \"\"\"\n    Preprocesses the input image:\n    - Loads the image from the given path.\n    - Resizes it to the target size.\n    - Normalizes pixel values between 0 and 1.\n    Returns:\n        The preprocessed image as a NumPy array ready for model inference.\n    \"\"\"",
        "detail": "cnn_inference",
        "documentation": {}
    },
    {
        "label": "image_path",
        "kind": 5,
        "importPath": "cnn_inference",
        "description": "cnn_inference",
        "peekOfCode": "image_path = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\dataset\\test\\open_door\\cropped_region_39743_91.jpg\"\n# Preprocess the image\ninput_image = preprocess_image(image_path)\n# Perform inference\npredictions = model.predict(input_image)\n# The output of `model.predict` will be a probability distribution for each class\nprint(\"Predictions:\", predictions)\n# Get the class with the highest probability\npredicted_class = np.argmax(predictions, axis=1)  # Index of the highest probability\nprint(f\"Predicted Class: {predicted_class}\")",
        "detail": "cnn_inference",
        "documentation": {}
    },
    {
        "label": "input_image",
        "kind": 5,
        "importPath": "cnn_inference",
        "description": "cnn_inference",
        "peekOfCode": "input_image = preprocess_image(image_path)\n# Perform inference\npredictions = model.predict(input_image)\n# The output of `model.predict` will be a probability distribution for each class\nprint(\"Predictions:\", predictions)\n# Get the class with the highest probability\npredicted_class = np.argmax(predictions, axis=1)  # Index of the highest probability\nprint(f\"Predicted Class: {predicted_class}\")\n# Define your class labels (these must match the order used during training)\nclass_labels = ['closed door', 'container face', 'container side', 'handholds', 'open door']",
        "detail": "cnn_inference",
        "documentation": {}
    },
    {
        "label": "predictions",
        "kind": 5,
        "importPath": "cnn_inference",
        "description": "cnn_inference",
        "peekOfCode": "predictions = model.predict(input_image)\n# The output of `model.predict` will be a probability distribution for each class\nprint(\"Predictions:\", predictions)\n# Get the class with the highest probability\npredicted_class = np.argmax(predictions, axis=1)  # Index of the highest probability\nprint(f\"Predicted Class: {predicted_class}\")\n# Define your class labels (these must match the order used during training)\nclass_labels = ['closed door', 'container face', 'container side', 'handholds', 'open door']\n# Get the predicted class label\npredicted_label = class_labels[predicted_class[0]]",
        "detail": "cnn_inference",
        "documentation": {}
    },
    {
        "label": "predicted_class",
        "kind": 5,
        "importPath": "cnn_inference",
        "description": "cnn_inference",
        "peekOfCode": "predicted_class = np.argmax(predictions, axis=1)  # Index of the highest probability\nprint(f\"Predicted Class: {predicted_class}\")\n# Define your class labels (these must match the order used during training)\nclass_labels = ['closed door', 'container face', 'container side', 'handholds', 'open door']\n# Get the predicted class label\npredicted_label = class_labels[predicted_class[0]]\nprint(f\"Predicted Label: {predicted_label}\")",
        "detail": "cnn_inference",
        "documentation": {}
    },
    {
        "label": "class_labels",
        "kind": 5,
        "importPath": "cnn_inference",
        "description": "cnn_inference",
        "peekOfCode": "class_labels = ['closed door', 'container face', 'container side', 'handholds', 'open door']\n# Get the predicted class label\npredicted_label = class_labels[predicted_class[0]]\nprint(f\"Predicted Label: {predicted_label}\")",
        "detail": "cnn_inference",
        "documentation": {}
    },
    {
        "label": "predicted_label",
        "kind": 5,
        "importPath": "cnn_inference",
        "description": "cnn_inference",
        "peekOfCode": "predicted_label = class_labels[predicted_class[0]]\nprint(f\"Predicted Label: {predicted_label}\")",
        "detail": "cnn_inference",
        "documentation": {}
    },
    {
        "label": "resize_image",
        "kind": 2,
        "importPath": "cnn_sorting",
        "description": "cnn_sorting",
        "peekOfCode": "def resize_image(image, max_width=1920, max_height=1080):\n    \"\"\"Resizes the image to fit within the specified dimensions while maintaining aspect ratio.\"\"\"\n    height, width = image.shape[:2]\n    scaling_factor = min(max_width / width, max_height / height)\n    new_size = (int(width * scaling_factor), int(height * scaling_factor))\n    return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n# Process each image in the source directory\nfor image_name in os.listdir(source_dir):\n    if image_name.endswith(('.jpg', '.jpeg', '.png')):\n        image_path = os.path.join(source_dir, image_name)",
        "detail": "cnn_sorting",
        "documentation": {}
    },
    {
        "label": "source_dir",
        "kind": 5,
        "importPath": "cnn_sorting",
        "description": "cnn_sorting",
        "peekOfCode": "source_dir = r'C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops'\n# Define the target directory where images will be organized by class\nclosed_door_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\closed_door\"\ncontainer_side_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\cont_sides\"\nopen_door_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\open_door\"\nhandhold_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\handholds\"\ncont_face_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\cont_face\"\n# Create a list of class identifiers\nclass_identifiers = ['1', '2', '3', '4', '5']  # Add more class identifiers as needed\ndef resize_image(image, max_width=1920, max_height=1080):",
        "detail": "cnn_sorting",
        "documentation": {}
    },
    {
        "label": "closed_door_dir",
        "kind": 5,
        "importPath": "cnn_sorting",
        "description": "cnn_sorting",
        "peekOfCode": "closed_door_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\closed_door\"\ncontainer_side_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\cont_sides\"\nopen_door_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\open_door\"\nhandhold_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\handholds\"\ncont_face_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\cont_face\"\n# Create a list of class identifiers\nclass_identifiers = ['1', '2', '3', '4', '5']  # Add more class identifiers as needed\ndef resize_image(image, max_width=1920, max_height=1080):\n    \"\"\"Resizes the image to fit within the specified dimensions while maintaining aspect ratio.\"\"\"\n    height, width = image.shape[:2]",
        "detail": "cnn_sorting",
        "documentation": {}
    },
    {
        "label": "container_side_dir",
        "kind": 5,
        "importPath": "cnn_sorting",
        "description": "cnn_sorting",
        "peekOfCode": "container_side_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\cont_sides\"\nopen_door_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\open_door\"\nhandhold_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\handholds\"\ncont_face_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\cont_face\"\n# Create a list of class identifiers\nclass_identifiers = ['1', '2', '3', '4', '5']  # Add more class identifiers as needed\ndef resize_image(image, max_width=1920, max_height=1080):\n    \"\"\"Resizes the image to fit within the specified dimensions while maintaining aspect ratio.\"\"\"\n    height, width = image.shape[:2]\n    scaling_factor = min(max_width / width, max_height / height)",
        "detail": "cnn_sorting",
        "documentation": {}
    },
    {
        "label": "open_door_dir",
        "kind": 5,
        "importPath": "cnn_sorting",
        "description": "cnn_sorting",
        "peekOfCode": "open_door_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\open_door\"\nhandhold_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\handholds\"\ncont_face_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\cont_face\"\n# Create a list of class identifiers\nclass_identifiers = ['1', '2', '3', '4', '5']  # Add more class identifiers as needed\ndef resize_image(image, max_width=1920, max_height=1080):\n    \"\"\"Resizes the image to fit within the specified dimensions while maintaining aspect ratio.\"\"\"\n    height, width = image.shape[:2]\n    scaling_factor = min(max_width / width, max_height / height)\n    new_size = (int(width * scaling_factor), int(height * scaling_factor))",
        "detail": "cnn_sorting",
        "documentation": {}
    },
    {
        "label": "handhold_dir",
        "kind": 5,
        "importPath": "cnn_sorting",
        "description": "cnn_sorting",
        "peekOfCode": "handhold_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\handholds\"\ncont_face_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\cont_face\"\n# Create a list of class identifiers\nclass_identifiers = ['1', '2', '3', '4', '5']  # Add more class identifiers as needed\ndef resize_image(image, max_width=1920, max_height=1080):\n    \"\"\"Resizes the image to fit within the specified dimensions while maintaining aspect ratio.\"\"\"\n    height, width = image.shape[:2]\n    scaling_factor = min(max_width / width, max_height / height)\n    new_size = (int(width * scaling_factor), int(height * scaling_factor))\n    return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)",
        "detail": "cnn_sorting",
        "documentation": {}
    },
    {
        "label": "cont_face_dir",
        "kind": 5,
        "importPath": "cnn_sorting",
        "description": "cnn_sorting",
        "peekOfCode": "cont_face_dir = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\\cont_face\"\n# Create a list of class identifiers\nclass_identifiers = ['1', '2', '3', '4', '5']  # Add more class identifiers as needed\ndef resize_image(image, max_width=1920, max_height=1080):\n    \"\"\"Resizes the image to fit within the specified dimensions while maintaining aspect ratio.\"\"\"\n    height, width = image.shape[:2]\n    scaling_factor = min(max_width / width, max_height / height)\n    new_size = (int(width * scaling_factor), int(height * scaling_factor))\n    return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n# Process each image in the source directory",
        "detail": "cnn_sorting",
        "documentation": {}
    },
    {
        "label": "class_identifiers",
        "kind": 5,
        "importPath": "cnn_sorting",
        "description": "cnn_sorting",
        "peekOfCode": "class_identifiers = ['1', '2', '3', '4', '5']  # Add more class identifiers as needed\ndef resize_image(image, max_width=1920, max_height=1080):\n    \"\"\"Resizes the image to fit within the specified dimensions while maintaining aspect ratio.\"\"\"\n    height, width = image.shape[:2]\n    scaling_factor = min(max_width / width, max_height / height)\n    new_size = (int(width * scaling_factor), int(height * scaling_factor))\n    return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n# Process each image in the source directory\nfor image_name in os.listdir(source_dir):\n    if image_name.endswith(('.jpg', '.jpeg', '.png')):",
        "detail": "cnn_sorting",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "common_obj_detection",
        "description": "common_obj_detection",
        "peekOfCode": "model = YOLO(\"yolov8n.pt\")  # You can specify different YOLO models here\ncrop_location = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\"\nfor crop in os.listdir(crop_location):\n    if crop.endswith(('.jpg', '.jpeg', '.png')):\n        # Load an image\n        img = cv2.imread(os.path.join(crop_location, crop))  # Replace with your image path\n        # Perform object detection\n        results = model.predict(source=img)  # Use 'cap' for video\n        # Process the results\n        detection_made = False",
        "detail": "common_obj_detection",
        "documentation": {}
    },
    {
        "label": "crop_location",
        "kind": 5,
        "importPath": "common_obj_detection",
        "description": "common_obj_detection",
        "peekOfCode": "crop_location = r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\crops\"\nfor crop in os.listdir(crop_location):\n    if crop.endswith(('.jpg', '.jpeg', '.png')):\n        # Load an image\n        img = cv2.imread(os.path.join(crop_location, crop))  # Replace with your image path\n        # Perform object detection\n        results = model.predict(source=img)  # Use 'cap' for video\n        # Process the results\n        detection_made = False\n        for result in results:",
        "detail": "common_obj_detection",
        "documentation": {}
    },
    {
        "label": "create_model",
        "kind": 2,
        "importPath": "create_cnn_model",
        "description": "create_cnn_model",
        "peekOfCode": "def create_model():\n    model = models.Sequential([\n        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(64, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Conv2D(128, (3, 3), activation='relu'),\n        layers.MaxPooling2D((2, 2)),\n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),",
        "detail": "create_cnn_model",
        "documentation": {}
    },
    {
        "label": "train_datagen",
        "kind": 5,
        "importPath": "create_cnn_model",
        "description": "create_cnn_model",
        "peekOfCode": "train_datagen = ImageDataGenerator(\n    rescale=1./255,         # Normalize pixel values between 0 and 1\n    rotation_range=20,      # Randomly rotate images\n    width_shift_range=0.2,  # Randomly shift horizontally\n    height_shift_range=0.2, # Randomly shift vertically\n    zoom_range=0.2,         # Randomly zoom in/out\n    horizontal_flip=True,   # Randomly flip images horizontally\n)\n# Validation data (no augmentation, just rescaling)\nvalidation_datagen = ImageDataGenerator(rescale=1./255)",
        "detail": "create_cnn_model",
        "documentation": {}
    },
    {
        "label": "validation_datagen",
        "kind": 5,
        "importPath": "create_cnn_model",
        "description": "create_cnn_model",
        "peekOfCode": "validation_datagen = ImageDataGenerator(rescale=1./255)\n# Load training and validation datasets\ntrain_data = train_datagen.flow_from_directory(\n    r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\dataset\\train\",\n    target_size=(128, 128),  # Resize images to 128x128\n    batch_size=32,\n    class_mode='categorical',  # For multi-class classification\n)\nvalidation_data = validation_datagen.flow_from_directory(\n    r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\dataset\\validation\",",
        "detail": "create_cnn_model",
        "documentation": {}
    },
    {
        "label": "train_data",
        "kind": 5,
        "importPath": "create_cnn_model",
        "description": "create_cnn_model",
        "peekOfCode": "train_data = train_datagen.flow_from_directory(\n    r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\dataset\\train\",\n    target_size=(128, 128),  # Resize images to 128x128\n    batch_size=32,\n    class_mode='categorical',  # For multi-class classification\n)\nvalidation_data = validation_datagen.flow_from_directory(\n    r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\dataset\\validation\",\n    target_size=(128, 128),\n    batch_size=32,",
        "detail": "create_cnn_model",
        "documentation": {}
    },
    {
        "label": "validation_data",
        "kind": 5,
        "importPath": "create_cnn_model",
        "description": "create_cnn_model",
        "peekOfCode": "validation_data = validation_datagen.flow_from_directory(\n    r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\dataset\\validation\",\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical',\n)\nmodel = create_model()\nmodel.compile(\n    optimizer='adam', \n    loss='categorical_crossentropy',",
        "detail": "create_cnn_model",
        "documentation": {}
    },
    {
        "label": "model",
        "kind": 5,
        "importPath": "create_cnn_model",
        "description": "create_cnn_model",
        "peekOfCode": "model = create_model()\nmodel.compile(\n    optimizer='adam', \n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\nhistory = model.fit(\n    train_data,\n    validation_data=validation_data,\n    epochs=20,  # Number of training epochs",
        "detail": "create_cnn_model",
        "documentation": {}
    },
    {
        "label": "history",
        "kind": 5,
        "importPath": "create_cnn_model",
        "description": "create_cnn_model",
        "peekOfCode": "history = model.fit(\n    train_data,\n    validation_data=validation_data,\n    epochs=20,  # Number of training epochs\n)\n# Test dataset\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_data = test_datagen.flow_from_directory(\n    r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\dataset\\test\",\n    target_size=(128, 128),",
        "detail": "create_cnn_model",
        "documentation": {}
    },
    {
        "label": "test_datagen",
        "kind": 5,
        "importPath": "create_cnn_model",
        "description": "create_cnn_model",
        "peekOfCode": "test_datagen = ImageDataGenerator(rescale=1./255)\ntest_data = test_datagen.flow_from_directory(\n    r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\dataset\\test\",\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical',\n)\n# Evaluate the model\ntest_loss, test_accuracy = model.evaluate(test_data)\nprint(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")",
        "detail": "create_cnn_model",
        "documentation": {}
    },
    {
        "label": "test_data",
        "kind": 5,
        "importPath": "create_cnn_model",
        "description": "create_cnn_model",
        "peekOfCode": "test_data = test_datagen.flow_from_directory(\n    r\"C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\dataset\\test\",\n    target_size=(128, 128),\n    batch_size=32,\n    class_mode='categorical',\n)\n# Evaluate the model\ntest_loss, test_accuracy = model.evaluate(test_data)\nprint(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n# Plot accuracy",
        "detail": "create_cnn_model",
        "documentation": {}
    },
    {
        "label": "resize_image",
        "kind": 2,
        "importPath": "heuristic_cropping",
        "description": "heuristic_cropping",
        "peekOfCode": "def resize_image(image, max_width=1920*2, max_height=1080*2):\n    \"\"\"Resizes the image to fit within the specified dimensions while maintaining aspect ratio.\"\"\"\n    height, width = image.shape[:2]\n    scaling_factor = min(max_width / width, max_height / height)\n    new_size = (int(width * scaling_factor), int(height * scaling_factor))\n    return cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\ndef resize_to_height(image, target_height=1024):\n    \"\"\"Resizes the image to a consistent height while maintaining aspect ratio.\"\"\"\n    height, width = image.shape[:2]\n    scaling_factor = target_height / height",
        "detail": "heuristic_cropping",
        "documentation": {}
    },
    {
        "label": "resize_to_height",
        "kind": 2,
        "importPath": "heuristic_cropping",
        "description": "heuristic_cropping",
        "peekOfCode": "def resize_to_height(image, target_height=1024):\n    \"\"\"Resizes the image to a consistent height while maintaining aspect ratio.\"\"\"\n    height, width = image.shape[:2]\n    scaling_factor = target_height / height\n    new_width = int(width * scaling_factor)\n    new_size = (new_width, target_height)  # (width, height)\n    resized_image = cv2.resize(image, new_size, interpolation=cv2.INTER_AREA)\n    return resized_image, scaling_factor\ntrnv_image_loc = r'C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\trnvopendoor'\nfor trnv_image in os.listdir(trnv_image_loc):",
        "detail": "heuristic_cropping",
        "documentation": {}
    },
    {
        "label": "trnv_image_loc",
        "kind": 5,
        "importPath": "heuristic_cropping",
        "description": "heuristic_cropping",
        "peekOfCode": "trnv_image_loc = r'C:\\Users\\c883206\\OneDrive - BNSF Railway\\RoboRailCop\\2025-01-16_all_trnv_images\\trnvopendoor'\nfor trnv_image in os.listdir(trnv_image_loc):\n    if trnv_image.endswith('.jpg'):\n        # Load the image in grayscale\n        image = cv2.imread(os.path.join(trnv_image_loc, trnv_image), cv2.IMREAD_GRAYSCALE)\n        # Step 1: Resize the image to a consistent height\n        resized_image, scaling_factor = resize_to_height(image)\n        # Step 2: Apply histogram equalization to enhance contrast\n        equalized_image = cv2.equalizeHist(image)\n        # Step 3: Detect vertical edges using the Sobel filter",
        "detail": "heuristic_cropping",
        "documentation": {}
    }
]